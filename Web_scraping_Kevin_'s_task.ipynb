{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fccd3b19-ce2b-4dea-b1bf-944be709c6bb",
   "metadata": {},
   "source": [
    "# Task: Web Scraping data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df3953c-6f4c-4b95-b65d-38429f3376e9",
   "metadata": {},
   "source": [
    "Web scraping is a technique used to extract data from websites. It involves writing code to automatically collect information from web pages, which can then be processed and used for various purposes, such as data analysis, market research, or content aggregation. Common tools and libraries for web scraping include:\n",
    "\n",
    "1. **Python Libraries**:\n",
    "   - **BeautifulSoup**: A Python library for parsing HTML and XML documents, useful for extracting specific elements from a webpage.\n",
    "   - **Scrapy**: A web crawling framework that allows you to build and run web spiders to scrape websites.\n",
    "   - **Selenium**: A tool for automating web browsers, often used to scrape data from dynamically loaded content (e.g., JavaScript-heavy websites).\n",
    "\n",
    "2. **Web Scraping Process**:\n",
    "   - **Step 1**: Identify the target website and determine if the data you want is publicly available.\n",
    "   - **Step 2**: Inspect the structure of the website (HTML, CSS) using browser developer tools to identify the elements containing the data.\n",
    "   - **Step 3**: Write a scraper using libraries like BeautifulSoup or Scrapy to access and extract the data.\n",
    "   - **Step 4**: Process and store the extracted data in a usable format, such as CSV or a database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207a650f-6a89-4538-a6d8-eff32a7ffc98",
   "metadata": {},
   "source": [
    "### Installing some necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc29400f-fa4b-422f-b108-de86b1115277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.24.0-py3-none-any.whl (9.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.6 MB 27 kB/s eta 0:00:013\n",
      "\u001b[?25hCollecting trio~=0.17\n",
      "  Downloading trio-0.26.2-py3-none-any.whl (475 kB)\n",
      "\u001b[K     |████████████████████████████████| 475 kB 201 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3[socks]<3,>=1.26\n",
      "  Downloading urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
      "\u001b[K     |████████████████████████████████| 121 kB 42 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2021.10.8\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "\u001b[K     |████████████████████████████████| 167 kB 51 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting websocket-client~=1.8\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 101 kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.8/dist-packages (from selenium) (4.9.0)\n",
      "Requirement already satisfied: exceptiongroup; python_version < \"3.11\" in /usr/local/lib/python3.8/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.8/dist-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: idna in /usr/lib/python3/dist-packages (from trio~=0.17->selenium) (2.8)\n",
      "Collecting sortedcontainers\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6; extra == \"socks\"\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Installing collected packages: outcome, sortedcontainers, trio, pysocks, urllib3, certifi, websocket-client, wsproto, trio-websocket, selenium\n",
      "Successfully installed certifi-2024.8.30 outcome-1.3.0.post0 pysocks-1.7.1 selenium-4.24.0 sortedcontainers-2.4.0 trio-0.26.2 trio-websocket-0.11.1 urllib3-2.2.2 websocket-client-1.8.0 wsproto-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8484d98a-64dc-4c29-a96e-0252fbe6a5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (2.31.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.8/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.8/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests) (3.3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e4d10cc-8958-4043-a3e8-91e0f0752055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from webdriver-manager) (2.31.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from webdriver-manager) (23.2)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.8/site-packages (from requests->webdriver-manager) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->webdriver-manager) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->webdriver-manager) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.8/site-packages (from requests->webdriver-manager) (2.2.2)\n",
      "Installing collected packages: python-dotenv, webdriver-manager\n",
      "Successfully installed python-dotenv-1.0.1 webdriver-manager-4.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0050581-198d-42c4-9fd3-c17aaef2acb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting zipfile36\n",
      "  Downloading zipfile36-0.1.3-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: zipfile36\n",
      "Successfully installed zipfile36-0.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install zipfile36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20168c96-5ba0-4f1a-96e9-59ea5efd7fa0",
   "metadata": {},
   "source": [
    "### Necessary librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60b7dd9-b868-4bac-a7be-2cedfc9e40f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import zipfile\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e19fed-4767-418b-b8c3-50a4f834eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory to store the downloaded images\n",
    "def create_directory(directory_name):\n",
    "    if not os.path.exists(directory_name):\n",
    "        os.makedirs(directory_name)\n",
    "    return directory_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e58cf2a-f4f5-4c88-a0ee-65b877d68f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download images\n",
    "def download_image(image_url, save_folder, image_num):\n",
    "    try:\n",
    "        img_data = requests.get(image_url).content\n",
    "        file_name = os.path.join(save_folder, f'image_{image_num}.jpg')\n",
    "        with open(file_name, 'wb') as handler:\n",
    "            handler.write(img_data)\n",
    "        print(f\"Downloaded: {file_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {image_url}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a8561b-0b7c-405b-9420-3d86aa17e95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a ZIP file\n",
    "def create_zip_file(folder_name, zip_file_name):\n",
    "    with zipfile.ZipFile(zip_file_name, 'w') as zipf:\n",
    "        for root, dirs, files in os.walk(folder_name):\n",
    "            for file in files:\n",
    "                zipf.write(os.path.join(root, file), file)\n",
    "    print(f\"All images compressed into {zip_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd50b2a-d29f-459c-b60f-04a7ed842669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Selenium WebDriver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e641afc8-7602-418d-925c-1ff378023456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape and download images from Pinterest\n",
    "def scrape_pinterest_images(query, limit=10, download_folder='pinterest_images', zip_file_name='images.zip'):\n",
    "    # Create a directory to store the images\n",
    "    save_folder = create_directory(download_folder)\n",
    "\n",
    "    search_url = f\"https://www.pinterest.com/search/pins/?q={query}\"\n",
    "    driver.get(search_url)\n",
    "    time.sleep(5)  # Let the page load\n",
    "\n",
    "    images = set()\n",
    "    scroll_pause = 2\n",
    "    scrolls = 0\n",
    "    image_count = 0\n",
    "\n",
    "    while image_count < limit:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(scroll_pause)\n",
    "\n",
    "        # Find image elements\n",
    "        img_elements = driver.find_elements(By.CSS_SELECTOR, \"img\")\n",
    "        for img in img_elements:\n",
    "            img_url = img.get_attribute('src')\n",
    "            if img_url and img_url not in images:\n",
    "                images.add(img_url)\n",
    "                download_image(img_url, save_folder, image_count + 1)\n",
    "                image_count += 1\n",
    "                if image_count >= limit:\n",
    "                    break\n",
    "\n",
    "        scrolls += 1\n",
    "        if scrolls > 10:  # Safety stop to avoid scrolling too far\n",
    "            break\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    # Create a ZIP file with all downloaded images\n",
    "    create_zip_file(save_folder, zip_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bd56699-b7ba-459d-a58d-e2ebad80f375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: beauty_images/image_1.jpg\n",
      "Downloaded: beauty_images/image_2.jpg\n",
      "Downloaded: beauty_images/image_3.jpg\n",
      "Downloaded: beauty_images/image_4.jpg\n",
      "Downloaded: beauty_images/image_5.jpg\n",
      "Downloaded: beauty_images/image_6.jpg\n",
      "Downloaded: beauty_images/image_7.jpg\n",
      "Downloaded: beauty_images/image_8.jpg\n",
      "Downloaded: beauty_images/image_9.jpg\n",
      "Downloaded: beauty_images/image_10.jpg\n",
      "Downloaded: beauty_images/image_11.jpg\n",
      "Downloaded: beauty_images/image_12.jpg\n",
      "Downloaded: beauty_images/image_13.jpg\n",
      "Downloaded: beauty_images/image_14.jpg\n",
      "Downloaded: beauty_images/image_15.jpg\n",
      "Downloaded: beauty_images/image_16.jpg\n",
      "Downloaded: beauty_images/image_17.jpg\n",
      "Downloaded: beauty_images/image_18.jpg\n",
      "Downloaded: beauty_images/image_19.jpg\n",
      "Downloaded: beauty_images/image_20.jpg\n",
      "All images compressed into beauty_images.zip\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "scrape_pinterest_images('beauty products', limit=20, download_folder='beauty_images', zip_file_name='beauty_images.zip')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91f0632-b688-4916-b0be-473b589fca23",
   "metadata": {},
   "source": [
    "## The code has work succesfuly but the result have some issues such as the dimensions of the images, the numbers of the images. Other difficulty is about the *Chromedriver*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
